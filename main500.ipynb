{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "2a4fdd0f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "2a4fdd0f",
        "outputId": "d758fb02-8b42-4705-d4bd-bcaa6df69ea7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from copy import deepcopy as dc\n",
        "from torch.utils.data import DataLoader\n",
        "import glob\n",
        "import random\n",
        "\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "file = '../../archive/YUM.csv'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "files = glob.glob(\"../../archive/*.csv\")\n",
        "# random.shuffle(files)\n",
        "# files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2>Model</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2>Training</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "iue5WvTxmVKB",
      "metadata": {
        "id": "iue5WvTxmVKB"
      },
      "outputs": [],
      "source": [
        "from Modules.train import train_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "1jgb1aJ3lxlQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jgb1aJ3lxlQ",
        "outputId": "2a25db36-4872-44e4-feca-4d26bad49f96"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load data into pytorch dataset\n",
        "\n",
        "from Modules.dataset_class import TimeSeriesDataset\n",
        "from Modules.preprocess import process_data\n",
        "def train_on_file(file, model, num_epochs, loss_function, optimizer, device):\n",
        "\n",
        "    print(\"PROCESSING \"+ file)\n",
        "    _, _, X_train, X_test, y_train, y_test, _ = process_data(file)\n",
        "    train_dataset = TimeSeriesDataset(X_train, y_train)\n",
        "    test_dataset = TimeSeriesDataset(X_test, y_test)\n",
        "    X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
        "\n",
        "    # create batches\n",
        "    batch_size = 16\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model = train_model(num_epochs, model, loss_function, optimizer, train_loader,test_loader, device)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_all(files, input_model, num_epochs, loss_function, optimizer, device):\n",
        "    model = input_model\n",
        "    save = 1\n",
        "    for file in files:\n",
        "        model = train_on_file(file, model, num_epochs, loss_function, optimizer, device)\n",
        "        if save % 5 == 0:\n",
        "            torch.save(model, 'checkpoints/forecast'+str(save)+'.pt')\n",
        "        save += 1\n",
        "\n",
        "    torch.save(model, 'forecast_final_GRU.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from Modules.model import GRU\n",
        "\n",
        "model = GRU(30, 1, 64, 16, 1)\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "loss_function = nn.HuberLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# files = sorted(glob.glob(\"archive/*.csv\"))[:10]\n",
        "files = glob.glob(\"../..archive/*.csv\")\n",
        "random.shuffle(files)\n",
        "\n",
        "files_list_path = \"../../checkpoints/filenames.txt\"\n",
        "with open(files_list_path, 'w') as file:\n",
        "    # Write each element of the string array to the file\n",
        "    for item in files:\n",
        "        file.write(item + '\\n')\n",
        "\n",
        "\n",
        "\n",
        "train_all(files, model, num_epochs, loss_function, optimizer, device)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
