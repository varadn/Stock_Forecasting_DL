{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import yfinance as yf\n",
    "from yahoo_fin import stock_info\n",
    "from Modules.preprocess import process_data\n",
    "from copy import deepcopy as dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class For a Preprocessed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPDataset:\n",
    "    def __init__(self, x, y, x_train, x_test, y_train, y_test, scaler):\n",
    "        self._x = x\n",
    "        self._y = y\n",
    "        self.x_train = x_train\n",
    "        self.x_test = x_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.scaler = scaler\n",
    "    \n",
    "    def get_x_train(self):\n",
    "        return self.x_train\n",
    "    \n",
    "    def get_x_test(self):\n",
    "        return self.x_test\n",
    "    \n",
    "    def get_y_train(self):\n",
    "        return self.y_train\n",
    "    \n",
    "    def get_y_test(self):\n",
    "        return self.y_test\n",
    "    \n",
    "    def get_scaler(self):\n",
    "        return self.scaler\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function To Loop the Preprocessing Of .csv Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_metrics(tickers):\n",
    "    # Create list to store preprocessed datasets\n",
    "    preparedDataSets = list()\n",
    "    # Loop preprocess all datasets\n",
    "    for ticker in tickers:\n",
    "        file = '../../current/'+ticker+'.csv'\n",
    "        X, y, X_train, X_test, y_train, y_test, scaler = process_data(file)\n",
    "        ppd = PPDataset(X, y, X_train, X_test, y_train, y_test, scaler)\n",
    "        preparedDataSets.append(ppd)\n",
    "    # return list\n",
    "    return preparedDataSets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function To Loop the Processing of Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_predictions(preparedDataSets, lookback, outmodel):\n",
    "    test_preds_list = list()\n",
    "    for dataset in preparedDataSets:\n",
    "        x_test = dataset.get_x_test()\n",
    "        scaler = dataset.get_scaler()\n",
    "        test_predictions = outmodel(x_test.to(device)).detach().cpu().numpy().flatten()\n",
    "\n",
    "        dummies = np.zeros((x_test.shape[0], lookback+1))\n",
    "        dummies[:, 0] = test_predictions\n",
    "        dummies = scaler.inverse_transform(dummies)\n",
    "\n",
    "        test_predictions = dc(dummies[:, 0])\n",
    "        test_preds_list.append(test_predictions)\n",
    "\n",
    "    return test_preds_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions To Output RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python program to get average of a list \n",
    "def average(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "\n",
    "def output_rmse(tickers, test_predictions, preparedDataSets):\n",
    "    i = 0\n",
    "    rmse_list = list()\n",
    "    while i < len(tickers): \n",
    "        # Convert test prediction to np array\n",
    "        test_prediction_np = np.array(test_predictions[i])\n",
    "        # Call prepared datasets[i]\n",
    "        preppedDataset = preparedDataSets[i]\n",
    "        # Convert y_test to np array\n",
    "        y_test_np = np.array(preppedDataset.get_y_test())\n",
    "        # Calculate RMSE\n",
    "        rmse = np.sqrt(np.mean((test_prediction_np - y_test_np) ** 2))\n",
    "        # print rmse for ticker\n",
    "        print(\"RMSE for \"+str(tickers[i])+\": \"+str(rmse))\n",
    "        rmse_list.append(rmse)\n",
    "        i = i + 1\n",
    "    avg_rmse = average(rmse_list)\n",
    "    print(\"\\nAverage RMSE:\", avg_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather Preprocessed Data Into List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['AAPL','AMZ','BRK','META','SNAP']\n",
    "\n",
    "\n",
    "preparedDataSets = prepare_data_for_metrics(tickers)\n",
    "\n",
    "# preparedDataSets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model From pt File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (conv1d): Conv1d(30, 1, kernel_size=(1,), stride=(2,))\n",
       "  (init_linear): Linear(in_features=1, out_features=1, bias=True)\n",
       "  (lstm): LSTM(1, 64, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (linear): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (sequential): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=1, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): LSTM(1, 64, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outmodel = torch.load('../../forecast_final_LSTM.pt')\n",
    "outmodel.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 30\n",
    "\n",
    "test_predictions = get_test_predictions(preparedDataSets ,lookback, outmodel)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for AAPL: 155.1549969087763\n",
      "RMSE for AMZ: 889.3593667221879\n",
      "RMSE for BRK: 0.10172015416088039\n",
      "RMSE for META: 287.5861604353882\n",
      "RMSE for SNAP: 10.061774265473426\n",
      "\n",
      "Average RMSE: 268.4528036971973\n"
     ]
    }
   ],
   "source": [
    "output_rmse(tickers, test_predictions, preparedDataSets)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
